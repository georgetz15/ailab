{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-08T15:09:46.735900400Z",
     "start_time": "2024-06-08T15:09:41.695342200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\George Tzoupis\\anaconda3\\envs\\ailab\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "import torch\n",
    "\n",
    "from image_classification.models.mlp import MLPClassifier\n",
    "from image_classification.models.resnet import ResNetClassifier\n",
    "from layers import ResNetBlock\n",
    "import lightning.pytorch as pl\n",
    "import lightning.pytorch.loggers as pl_loggers\n",
    "import lightning.pytorch.callbacks as pl_callbacks\n",
    "\n",
    "from util import set_seed\n",
    "from weight_init import init_for_relu\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from datasets import FashionMNIST\n",
    "from experiment import train\n",
    "import sklearn.metrics as skm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def show_classification_results(test_dl, model, classnames):\n",
    "    ypred, ytrue = [], []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for x, y in test_dl:\n",
    "            pred = model(x.to(model.device))\n",
    "            ypred.extend(pred.argmax(-1).cpu().numpy().flatten())\n",
    "            ytrue.extend(y.cpu().numpy().flatten())\n",
    "\n",
    "    print(skm.classification_report(ytrue, ypred, target_names=classnames))\n",
    "    print(skm.confusion_matrix(ytrue, ypred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-08T15:09:46.751833900Z",
     "start_time": "2024-06-08T15:09:46.739413900Z"
    }
   },
   "id": "cfc411c34272bc3b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Param Grid using sklearn"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0845bce3c167eff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | classifier | Sequential | 309 K \n",
      "------------------------------------------\n",
      "309 K     Trainable params\n",
      "0         Non-trainable params\n",
      "309 K     Total params\n",
      "1.237     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "babee8e42e154f1ba6c997041e3d6abf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9bd97569b7fd4f42a5fd0cd6454e6f84"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "70f4369526714e58809b6dbada9bb611"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "920930b866324f6dadacc9435f31cf1b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2428143b50d54af28ccc53c1005578ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "44a344617ab944a684cce995f2370bac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77f38633ffe24d9a9ab49a588f015ddf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fdaa7f1732c94b4aa6d3736678def1fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d3489842e0a946eb8f1962f3cf2c59da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c5500fe73184e05bd32acb092adf276"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3e7e00b3f6f48e8b841fbb84e0b4276"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ab53f2906a847a9a2180212eb996a43"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top       0.72      0.81      0.77      1000\n",
      "     Trouser       0.99      0.93      0.96      1000\n",
      "    Pullover       0.58      0.62      0.60      1000\n",
      "       Dress       0.72      0.89      0.80      1000\n",
      "        Coat       0.56      0.72      0.63      1000\n",
      "      Sandal       0.93      0.86      0.89      1000\n",
      "       Shirt       0.46      0.15      0.23      1000\n",
      "     Sneaker       0.82      0.93      0.87      1000\n",
      "         Bag       0.94      0.93      0.94      1000\n",
      "  Ankle boot       0.92      0.91      0.92      1000\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.76      0.77      0.76     10000\n",
      "weighted avg       0.76      0.77      0.76     10000\n",
      "\n",
      "[[815   2  14 101  13   2  33   3  17   0]\n",
      " [  2 931  14  40   9   1   2   0   1   0]\n",
      " [ 19   1 616  12 278   0  69   1   3   1]\n",
      " [ 41   4   3 889  23   0  36   0   3   1]\n",
      " [  2   1 152  89 719   2  29   1   5   0]\n",
      " [  0   0   1   4   0 862   0 105   1  27]\n",
      " [243   2 262  82 231   3 152   0  25   0]\n",
      " [  0   0   0   0   0  31   0 926   0  43]\n",
      " [  3   2   7  11   8   9  12  16 930   2]\n",
      " [  0   0   0   3   0  17   0  73   0 907]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | classifier | Sequential | 1.2 M \n",
      "------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.920     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f89f46a627f3433e955df591ce574382"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "15fa091f3e544ba6b0b65ad6a2da36f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.seed_everything(42, True)\n",
    "\n",
    "train_dl, valid_dl, test_dl = FashionMNIST.get_dataloaders(batch_size=16,\n",
    "                                                           pin_memory=True,\n",
    "                                                           num_workers=4,\n",
    "                                                           persistent_workers=True)\n",
    "n_classes = len(train_dl.dataset.classes)\n",
    "\n",
    "# model = ResNetClassifier(\n",
    "#     n_classes=n_classes,\n",
    "#     opt='AdamW',\n",
    "#     lr=1e-1,\n",
    "#     wd=1e-4, ).apply(init_for_relu)\n",
    "\n",
    "param_grid = {\n",
    "    'n_features': [\n",
    "        (4, 8, 16, 32, 64, 128),\n",
    "        (8, 16, 32, 64, 128, 256),\n",
    "        (16, 32, 64, 128, 256, 512),\n",
    "    ],\n",
    "    'lr': [1e-3],\n",
    "    'wd': [1e-5],\n",
    "}\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    # model = MLPClassifier(\n",
    "    #     input_sz=28 * 28,\n",
    "    #     n_classes=n_classes,\n",
    "    #     **params,\n",
    "    # ).apply(init_for_relu)\n",
    "\n",
    "    model = ResNetClassifier(\n",
    "        n_classes=n_classes,\n",
    "        **params).apply(init_for_relu)\n",
    "\n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "        save_top_k=1,\n",
    "        monitor=\"accuracy/val\",\n",
    "        mode=\"max\",\n",
    "        filename=\"best-{epoch:02d}\",\n",
    "        save_last=True,\n",
    "    )\n",
    "\n",
    "    experiment_name = f\"ResNet-n_layers-{len(params['n_features'])}\"\n",
    "    tb_logger = pl_loggers.TensorBoardLogger(save_dir='./results',\n",
    "                                             name=experiment_name,\n",
    "                                             sub_dir=model.__class__.__name__)\n",
    "    trainer = pl.Trainer(max_epochs=10,\n",
    "                         # limit_train_batches=10,\n",
    "                         # limit_val_batches=10,\n",
    "                         callbacks=[\n",
    "                             checkpoint_callback,\n",
    "                         ],\n",
    "                         logger=tb_logger,\n",
    "                         )\n",
    "    trainer.fit(model=model,\n",
    "                train_dataloaders=train_dl,\n",
    "                val_dataloaders=valid_dl,\n",
    "                # ckpt_path='./results/fashion_mnist/version_5/checkpoints/best-epoch=04.ckpt'\n",
    "                )\n",
    "\n",
    "    show_classification_results(test_dl, model, test_dl.dataset.classes)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-06-08T15:09:53.523567200Z"
    }
   },
   "id": "c10f9d58693f3c15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    pl.seed_everything(42, True)\n",
    "\n",
    "    # Data prep\n",
    "    train_dl, valid_dl, test_dl = FashionMNIST.get_dataloaders(batch_size=16,\n",
    "                                                               pin_memory=True,\n",
    "                                                               num_workers=4,\n",
    "                                                               persistent_workers=True)\n",
    "\n",
    "    # Model setup\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    n_features = [\n",
    "        trial.suggest_int(\"n_features_l{}\".format(i), 4, 128, log=True) for i in range(n_layers)\n",
    "    ]\n",
    "    params = {\n",
    "        \"n_features\": n_features,\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0.2, 0.5),\n",
    "        \"lr\": trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True),\n",
    "        \"wd\": trial.suggest_float(\"wd\", 1e-5, 1e-1, log=True),\n",
    "        \"opt\": trial.suggest_categorical(\"opt\", [\"AdamW\", \"RMSprop\"]),\n",
    "    }\n",
    "    n_classes = len(train_dl.dataset.classes)\n",
    "    model = MLPClassifier(\n",
    "        input_sz=28 * 28,\n",
    "        n_classes=n_classes,\n",
    "        **params,\n",
    "    ).apply(init_for_relu)\n",
    "\n",
    "    # Trainer setup\n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "        save_top_k=1,\n",
    "        monitor=\"accuracy/val\",\n",
    "        mode=\"max\",\n",
    "        filename=\"best-{epoch:02d}\",\n",
    "        save_last=True,\n",
    "    )\n",
    "    tb_logger = pl_loggers.TensorBoardLogger(save_dir='./results',\n",
    "                                             name='fashion_mnist',\n",
    "                                             sub_dir=model.__class__.__name__)\n",
    "    trainer = pl.Trainer(max_epochs=5,\n",
    "                         limit_train_batches=10,\n",
    "                         limit_val_batches=10,\n",
    "                         callbacks=[\n",
    "                             checkpoint_callback,\n",
    "                         ],\n",
    "                         logger=tb_logger,\n",
    "                         )\n",
    "\n",
    "    # Train\n",
    "    trainer.fit(model=model,\n",
    "                train_dataloaders=train_dl,\n",
    "                val_dataloaders=valid_dl,\n",
    "                # ckpt_path='./results/fashion_mnist/version_5/checkpoints/best-epoch=04.ckpt'\n",
    "                )\n",
    "\n",
    "    return trainer.callback_metrics[\"accuracy/val\"].item()\n",
    "\n",
    "\n",
    "# Optuna study setup\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.HyperbandPruner())\n",
    "study.optimize(objective, n_trials=100, timeout=600, n_jobs=1)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59a5975187380749"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    pl.seed_everything(42, True)\n",
    "\n",
    "    params = {\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.5, log=True),\n",
    "        \"lr\": trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True),\n",
    "        \"wd\": trial.suggest_float(\"wd\", 1e-5, 1e-1, log=True),\n",
    "        \"opt\": trial.suggest_categorical(\"opt\", [\"SGD\", \"RAdam\"]),\n",
    "    }\n",
    "\n",
    "    data_module = FashionMNIST.FashionMNISTDataModule()\n",
    "    n_classes = data_module.n_classes\n",
    "    model = ResNetClassifier(\n",
    "        n_classes=n_classes,\n",
    "        **params).apply(init_for_relu)\n",
    "\n",
    "    trainer = train(model,\n",
    "                    data_module,\n",
    "                    monitored_metric='accuracy/val',\n",
    "                    mode='max',\n",
    "                    max_epochs=10,\n",
    "                    limit_train_batches=200)\n",
    "\n",
    "    return trainer.callback_metrics[\"accuracy/val\"].item()\n",
    "\n",
    "\n",
    "pruner = optuna.pruners.HyperbandPruner()\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n",
    "study.optimize(objective, n_trials=100, timeout=60 * 60, n_jobs=1)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "334eb883144387d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_module = FashionMNIST.FashionMNISTDataModule()\n",
    "ckpt_path = \"results/FashionMNIST/version_2/checkpoints/last.ckpt\"\n",
    "model = ResNetClassifier.load_from_checkpoint(ckpt_path)\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    save_top_k=1,\n",
    "    monitor=\"accuracy/val\",\n",
    "    mode=\"max\",\n",
    "    filename=\"best-{epoch:02d}\",\n",
    "    save_last=True,\n",
    ")\n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir='./results',\n",
    "                                         name=data_module.dataset_name,\n",
    "                                         sub_dir=model.__class__.__name__)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=40,\n",
    "                     callbacks=[\n",
    "                         checkpoint_callback,\n",
    "                     ],\n",
    "                     logger=tb_logger,\n",
    "                     )\n",
    "\n",
    "trainer.fit(model,\n",
    "            data_module,\n",
    "            ckpt_path=ckpt_path,\n",
    "            )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc8ce6eb314b5ff8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "855690a18a31a73d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
